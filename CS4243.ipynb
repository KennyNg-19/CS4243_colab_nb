{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ozyI21P2yyGD",
        "JQHwgUkQy5ch",
        "TYWVHsAZcB3X",
        "S2Q7xtQM3iHc"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30059e7f76554edeaebfde0ed47cb22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f32b89aee684497aeda207ea4168afb",
              "IPY_MODEL_51ed36da4009415eb75ea2e10b540dfc",
              "IPY_MODEL_74fdfbff676e4c3c830f45592759cc47"
            ],
            "layout": "IPY_MODEL_582f0ee5e71a49aba6e4cf92e4fa5159"
          }
        },
        "0f32b89aee684497aeda207ea4168afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a217e1bf7c1144449e17af9deb1be2b3",
            "placeholder": "​",
            "style": "IPY_MODEL_94dd1f666dfb401c972d62063d271db8",
            "value": "100%"
          }
        },
        "51ed36da4009415eb75ea2e10b540dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c35923bf34be437cb4057856dd450651",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eebff500f8174452a20b5f7afbaae825",
            "value": 46830571
          }
        },
        "74fdfbff676e4c3c830f45592759cc47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56fd522c16f5433ca34dc92971b713d5",
            "placeholder": "​",
            "style": "IPY_MODEL_9d624b2e9ea14d87ad56380ba0f6b9c6",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 152MB/s]"
          }
        },
        "582f0ee5e71a49aba6e4cf92e4fa5159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a217e1bf7c1144449e17af9deb1be2b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94dd1f666dfb401c972d62063d271db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c35923bf34be437cb4057856dd450651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eebff500f8174452a20b5f7afbaae825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56fd522c16f5433ca34dc92971b713d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d624b2e9ea14d87ad56380ba0f6b9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KennyNg-19/colab_nb/blob/main/CS4243.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS4243\n",
        "## Image Classification\n",
        "\n",
        "### Three classes: normal, carrying, threat\n"
      ],
      "metadata": {
        "id": "TlplzsytZPSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kenny Ng: MLP+CNN\n",
        "\n",
        "Junzhe: CNN+RNN\n",
        "\n",
        "Qini: VGG + resnet18 + LeNet\n",
        "\n",
        "11.7 周一 - preprocessing + 开始构建模型、\n",
        "\n",
        "11.8 周二 - 模型可以跑通\n",
        "\n",
        "周三 - eval 完成 + 讨论需不需要做更多 + 查漏补缺\n",
        "\n",
        "周四 - 写poster + 查漏补缺\n",
        "\n",
        "周五 - 讨论如何presentation + 查漏补缺\n",
        "\n",
        "周六 - presentation\n",
        "\n",
        "需要交的东西：\n",
        "\n",
        "poster，模型weights\n"
      ],
      "metadata": {
        "id": "tVirgHZZvgnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO:\n",
        "1. need to somehow load data and potentially use dataloader to split batch\n",
        "2. a DF ideally contains file names and label"
      ],
      "metadata": {
        "id": "YGFfjX2m9GdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Colab Notebooks/cs4243_smallest\n",
        "!ls"
      ],
      "metadata": {
        "id": "8ljHixTNvfb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "275cb6dd-1b80-4680-cc77-9fd725cde9b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/cs4243_smallest\n",
            "carrying  normal  threat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Library"
      ],
      "metadata": {
        "id": "EnFh9Tn-Z4sd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8d9hBaNBZMEs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from random import randint\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu setting\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('device', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djsK2DWZZtMd",
        "outputId": "5b684fa3-42b9-4e6d-fc05-b0a7a213a9cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "Uicp0Iu20i_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class to save the best model while training - \"best_model\"\n",
        "class SaveBestModel:\n",
        "    def __init__(\n",
        "        self, best_valid_loss=float('inf')\n",
        "    ):\n",
        "        self.best_valid_loss = best_valid_loss\n",
        "        \n",
        "    def __call__(\n",
        "        self, current_valid_loss, \n",
        "        epoch, model, optimizer, criterion\n",
        "    ):\n",
        "        if current_valid_loss < self.best_valid_loss:\n",
        "            self.best_valid_loss = current_valid_loss\n",
        "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
        "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
        "            torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, 'outputs/best_model.pth')\n",
        "            \n",
        "def save_model(epochs, model, optimizer, criterion):\n",
        "    print(f\"Saving final model...\")\n",
        "    torch.save({\n",
        "                'epoch': epochs,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, 'outputs/final_model.pth')"
      ],
      "metadata": {
        "id": "g1GG8MvlZnBA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# more info for the poster:\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def save_plots(train_acc, valid_acc, train_loss, valid_loss):\n",
        "    # accuracy\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(\n",
        "        train_acc, color='green', linestyle='-', \n",
        "        label='train accuracy'\n",
        "    )\n",
        "    plt.plot(\n",
        "        valid_acc, color='blue', linestyle='-', \n",
        "        label='validataion accuracy'\n",
        "    )\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig('outputs/accuracy.png')\n",
        "    \n",
        "    # loss\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(\n",
        "        train_loss, color='orange', linestyle='-', \n",
        "        label='train loss'\n",
        "    )\n",
        "    plt.plot(\n",
        "        valid_loss, color='red', linestyle='-', \n",
        "        label='validataion loss'\n",
        "    )\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('outputs/loss.png')\n",
        "\n",
        "def creat_viz_cm(confusion_matrix, label2class):\n",
        "    plt.figure(figsize=(15,10))\n",
        "\n",
        "    class_names = list(label2class.values())\n",
        "    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n"
      ],
      "metadata": {
        "id": "vJYonhtia1td"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the image and preprocessing\n",
        "Scaling and cropping, image enhancement, transformation to Tensor, normalization"
      ],
      "metadata": {
        "id": "DR5rxDRoZ2-H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vzzemEil2skw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "从输入到最后一个卷积特征feature map，就是进行信息抽象的过程，然后就经过全连接层/全局池化层的变换进行分类了，这个feature map的大小，可以是3*3，5*5，7*7等等。在这些尺寸中，如果尺寸太小，那么信息就丢失太严重，如果尺寸太大，信息的抽象层次不够高，计算量也更大，所以7*7的kernel大小是一个最好的平衡。\n",
        "\n",
        "另一方面，图像从大分辨率降低到小分辨率，降低倍数通常是2的指数次方，所以图像的输入是 kernel size *2的指数次方。"
      ],
      "metadata": {
        "id": "IJtBgz6fZgPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#labels\n",
        "classes_mapping = {'normal':0, 'carrying':1, 'threat':2}\n",
        "classes = list(classes_mapping.keys()) # 保持有序\n",
        "class_int = list(classes_mapping.values())\n",
        "classes, class_int\n"
      ],
      "metadata": {
        "id": "qVz49DNt4MbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b21a1a8-7231-4753-e8e7-a22c1dba6c0e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['normal', 'carrying', 'threat'], [0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### generate DataFrame for whole dataset"
      ],
      "metadata": {
        "id": "wNvVA41sAhw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_names = [] # ID\n",
        "targets = [] # labels\n",
        "# root_path='.'\n",
        "root_path = \"/content/drive/My Drive/Colab Notebooks/cs4243_smallest\"\n",
        "# root_path = \"/content/drive/My Drive/Colab Notebooks/cs4243_smallest\"\n",
        "\n",
        "# Mapping all img names & labels, 也是按照 classes顺序， ['normal', 'carrying', 'threat'] [0,1,2]\n",
        "for class_path in classes:                    \n",
        "    \n",
        "    # print(class_path)\n",
        "    path = os.path.join(root_path, class_path)\n",
        "    # 加上label_class_path\n",
        "    # img_names += [ class_path + \"/\" + img_name for img_name in os.listdir(path)]\n",
        "    print(class_path, len(os.listdir(path)))\n",
        "    img_names += os.listdir(path)\n",
        "    # print(os.listdir(self.path))\n",
        "    targets += [classes_mapping[class_path]] * len(os.listdir(path)) # all labels = 0 or 1 or 2\n",
        "\n",
        "# idx 完全mapping\n",
        "assert len(img_names) == len(targets), f'wrong no of all imgs, {len(img_names)}, {len(targets)}'\n",
        "df = pd.DataFrame({'ID':img_names, 'Label': targets})\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "kbdx6GIQAkbL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "1385a240-4e0b-4276-defc-089f8b370b62"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normal 1265\n",
            "carrying 1535\n",
            "threat 1052\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            ID  Label\n",
              "0         A0227648U_normal_44440.29563_100.png      0\n",
              "1    a015032m_040922_normal_13440.34438_30.png      0\n",
              "2         0218134_20220904_82510.38845_200.png      0\n",
              "3                       normal 20.10089_30.png      0\n",
              "4  1054350_20220904_normal_00040.37869_100.png      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec6e19d6-5525-4d07-9454-27419541c1e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0227648U_normal_44440.29563_100.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a015032m_040922_normal_13440.34438_30.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0218134_20220904_82510.38845_200.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>normal 20.10089_30.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1054350_20220904_normal_00040.37869_100.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec6e19d6-5525-4d07-9454-27419541c1e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec6e19d6-5525-4d07-9454-27419541c1e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec6e19d6-5525-4d07-9454-27419541c1e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split into df of train / test \n",
        "y = df['Label']\n",
        "X = df\n",
        "\n",
        "train_df, test_df, train_label, test_label = train_test_split(X, y, stratify=y, shuffle=True, test_size=0.2) \n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# torch.utils.data.random_split只是随机分，没有按照类别Stratified，比例：1857 ： 1535 ：1551\n",
        "# train_df, test_df = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# check Stratified split, 的class分布\n",
        "print(train_df.Label.value_counts()/train_df.Label.value_counts().sum())\n",
        "test_df.Label.value_counts()/test_df.Label.value_counts().sum()\n"
      ],
      "metadata": {
        "id": "-zsQdAcIB5w7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f834d0-7be0-4fc8-f09a-aa8d4ef56e1f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    0.398572\n",
            "0    0.328465\n",
            "2    0.272963\n",
            "Name: Label, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.398184\n",
              "0    0.328145\n",
              "2    0.273671\n",
              "Name: Label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JtgwJ-vq71Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Image preporcess: transform"
      ],
      "metadata": {
        "id": "vIRVPlx0BOCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "normalize = transforms.Normalize(mean, std)\n",
        "\n",
        "resize_H, resized_W = 7*2**5, 7*2**5 # 如果是toTensor前，最后一个transform操作(即输入到模型的input shape)，最好是kerel size, 3/5/7,* 2的指数次方\n",
        "resize = transforms.Resize([resize_H, resized_W])\n",
        "# resize = transforms.Resize([resize_H, resized_W],interpolation=torchvision.transforms.InterpolationMode.BILINEAR)\n",
        "\n",
        "crop_H, crop_W = 7*2**5, 7*2**5 # 如果是toTensor前，最后一个transform操作(即输入到模型的input shape)，最好是kerel size, 3/5/7,* 2的指数次方\n",
        "cent_crop = transforms.CenterCrop([crop_H, crop_W])\n",
        "\n",
        "transformations = transforms.Compose([resize,\n",
        "                                    #  cent_crop,\n",
        "                                    transforms.ToTensor(), # Tturn gray level from 0-255 into 0-1\n",
        "                                    normalize])  #  change 0-1 into (-1, 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "8AYOLPJbBQZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build Dataset & DataLoader"
      ],
      "metadata": {
        "id": "YbMLjN1_BCtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CS4243_dataset(Dataset): \n",
        "    \n",
        "    \n",
        "    def __init__(self, root_path , dataframe, transform=None):\n",
        "        \n",
        "        self.classes_mapping = {0:'normal', 1:'carrying', 2:'threat'}\n",
        "        self.df = dataframe    \n",
        "        self.transform = transform\n",
        "        self.root_path = root_path\n",
        "        \n",
        "        self.image_paths = self.df['ID'] #image names\n",
        "        self.labels = self.df['Label']\n",
        "                \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        img_path = self.image_paths[index] # 没有class_file_path\n",
        "        # print(img_path)\n",
        "        class_path = self.classes_mapping[self.labels[index]]\n",
        "        image = Image.open(os.path.join(self.root_path, class_path, img_path))\n",
        "        \n",
        "        target = torch.tensor(self.labels[index])\n",
        "      \n",
        "        if self.transform != None:\n",
        "            image = self.transform(image)\n",
        "          \n",
        "        return [image, target]\n",
        "       \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "metadata": {
        "id": "VROivFpxB_Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = CS4243_dataset(root_path, train_df, transform = transformations)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=2, shuffle = True, pin_memory=True)\n",
        "\n",
        "test_dataset = CS4243_dataset(root_path, test_df, transform = transformations)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=2, shuffle = True, pin_memory=True)\n",
        "\n",
        "\n",
        "for data in train_loader:\n",
        "    imgs, targets = data\n",
        "    print(imgs.shape)\n",
        "    print('labels:', targets, len(targets))\n",
        "    # 只输出一次\n",
        "    break"
      ],
      "metadata": {
        "id": "Ko5LVELh74q8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "bbb00794-0d36-483b-abbd-90c1a93f1d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-576f7aec4434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/cs4243_smallest/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCS4243_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Classification Models\n",
        "\n",
        "Implement image classificaiton by using:\n",
        "1. VGG as baseline\n",
        "2. Resnet18\n",
        "3. Transfer Learning\n"
      ],
      "metadata": {
        "id": "rAuSKAB0aCyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline: MLP"
      ],
      "metadata": {
        "id": "ozyI21P2yyGD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dqpsul1byxzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "GVItrJQcqYjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Way 1: LeNet from scratch"
      ],
      "metadata": {
        "id": "JQHwgUkQy5ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5_convnet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(LeNet5_convnet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,   50,  kernel_size=3,  padding=1 )\n",
        "        self.pool1  = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(50,  100,  kernel_size=3,  padding=1 )\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "    \n",
        "        self.linear1 = nn.Linear(4900, 100)\n",
        "        self.linear2 = nn.Linear(100,10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool1(x)\n",
        "    \n",
        "        x = self.conv2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = x.view(-1, 4900)\n",
        "        x = self.linear1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.linear2(x)\n",
        "    \n",
        "        return x"
      ],
      "metadata": {
        "id": "R90J2mqbqZPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Way 2: VGG from scratch\n",
        "Build a VGG"
      ],
      "metadata": {
        "id": "TYWVHsAZcB3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG_convnet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(VGG_convnet, self).__init__()\n",
        "     \n",
        "        self.conv1a = nn.Conv2d(3,   64,  kernel_size=3, padding=1 )\n",
        "        self.conv1b = nn.Conv2d(64,  64,  kernel_size=3, padding=1 )\n",
        "        self.pool1  = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.conv2a = nn.Conv2d(64,  128, kernel_size=3, padding=1 )\n",
        "        self.conv2b = nn.Conv2d(128, 128, kernel_size=3, padding=1 )\n",
        "        self.pool2  = nn.MaxPool2d(2,2)\n",
        "     \n",
        "        self.conv3a = nn.Conv2d(128, 256, kernel_size=3, padding=1 )\n",
        "        self.conv3b = nn.Conv2d(256, 256, kernel_size=3, padding=1 )\n",
        "        self.pool3  = nn.MaxPool2d(2,2)\n",
        "        \n",
        "        self.conv4a = nn.Conv2d(256, 512, kernel_size=3, padding=1 )\n",
        "        self.pool4  = nn.MaxPool2d(2,2)\n",
        "\n",
        "        # linear:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
        "        self.linear1 = nn.Linear(2048, 4096)\n",
        "        self.linear2 = nn.Linear(4096,4096)\n",
        "        self.linear3 = nn.Linear(4096, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1a(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv1b(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2a(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2b(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3a(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3b(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.conv4a(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        # linear:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
        "        x = x.view(-1, 2048)\n",
        "        x = self.linear1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear3(x) \n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "B8jLyMHjcGHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nn9ItL3Ez_xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Way 3: Resnet 18"
      ],
      "metadata": {
        "id": "S2Q7xtQM3iHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual_block(nn.Module):\n",
        "    def __init__(self, inchannel, outchannel, stride=1):\n",
        "        super(Residual_block, self).__init__()\n",
        "        self.left = nn.Sequential(\n",
        "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(outchannel),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(outchannel)\n",
        "        )\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or inchannel != outchannel:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(outchannel)\n",
        "            )\n",
        "            \n",
        "    def forward(self, x):\n",
        "        out = self.left(x)\n",
        "        out = out + self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, Residual_block, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inchannel = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.layer1 = self.make_layer(Residual_block, 64, 2, stride=1)\n",
        "        self.layer2 = self.make_layer(Residual_block, 128, 2, stride=2)\n",
        "        self.layer3 = self.make_layer(Residual_block, 256, 2, stride=2)        \n",
        "        self.layer4 = self.make_layer(Residual_block, 512, 2, stride=2)        \n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "    def make_layer(self, block, channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.inchannel, channels, stride))\n",
        "            self.inchannel = channels\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(Residual_block)"
      ],
      "metadata": {
        "id": "-1UoBY3w3owT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "h4iGqQKS2GiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net=VGG_convnet()\n",
        "# net=LeNet5_convnet()\n",
        "# net = MLP()\n",
        "# net = ResNet18()\n",
        "\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDR40Q0K2nwa",
        "outputId": "2774db98-2fb9-427e-eca0-323c9ea87baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG_convnet(\n",
            "  (conv1a): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv1b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2a): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3a): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4a): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (linear1): Linear(in_features=2048, out_features=4096, bias=True)\n",
            "  (linear2): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (linear3): Linear(in_features=4096, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# send to gpu\n",
        "net = net.to(device)\n",
        "mean = torch.FloatTensor(mean)\n",
        "mean = mean.to(device)\n",
        "std = torch.FloatTensor(std)\n",
        "std = std.to(device)"
      ],
      "metadata": {
        "id": "YP4Ncn120DYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "my_lr=0.25 \n",
        "bs= 128\n",
        "epochs = 1\n",
        "\n",
        "# initialize SaveBestModel class\n",
        "save_best_model = SaveBestModel()"
      ],
      "metadata": {
        "id": "azzgHCao0ID4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    print('===== Training =====')\n",
        "    running_loss=0\n",
        "    counter=0\n",
        "\n",
        "    for i, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "        counter += 1\n",
        "        X_train, y_train = data\n",
        "        X_train = X_train.to(device)\n",
        "        y_train = y_train.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(X_train)\n",
        "        # calculate the loss\n",
        "        loss = criterion(outputs, y_train)\n",
        "        running_loss += loss.item()\n",
        "        # calculate the accuracy\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        running_correct += (preds == y_train).sum().item()\n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "        # update the optimizer parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        # loss and accuracy for the complete epoch\n",
        "        epoch_loss = running_loss / counter\n",
        "        epoch_acc = 100. * (running_correct / len(train_loader.dataset))\n",
        "    return epoch_loss, epoch_acc\n",
        "  "
      ],
      "metadata": {
        "id": "K2sBy0N4T_F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, test_loader, criterion):\n",
        "    model.eval() # close BN and dropout layer\n",
        "    print('===== Validation =====')\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            counter += 1\n",
        "            \n",
        "            X_test, y_test = data\n",
        "            X_test = X_test.to(device)\n",
        "            y_test = y_test.to(device)\n",
        "            # forward pass\n",
        "            outputs = model(X_test)\n",
        "            # calculate the loss\n",
        "            loss = criterion(outputs, y_test)\n",
        "            running_loss += loss.item()\n",
        "            # calculate the accuracy\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            running_correct += (preds == y_test).sum().item()\n",
        "        \n",
        "    # loss and accuracy for the complete epoch\n",
        "    epoch_loss = running_loss / counter\n",
        "    epoch_acc = 100. * (running_correct / len(test_loader.dataset))\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "HWdz6MB7XuOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start=time.time()\n",
        "train_loss, valid_loss = [], []\n",
        "train_acc, valid_acc = [], []\n",
        "for epoch in range(epochs):\n",
        "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
        "    \n",
        "    # divide the learning rate by 2 at epoch 10, 14 and 18\n",
        "    if epoch==10 or epoch == 14 or epoch==18:\n",
        "        my_lr = my_lr / 2\n",
        "    \n",
        "    # give the current learning rate for the optimizer\n",
        "    optimizer=torch.optim.SGD(net.parameters(), lr=my_lr, momentum=0.9, weight_decay=5e-4 )\n",
        "        \n",
        "    train_epoch_loss, train_epoch_acc = train(net, train_loader, \n",
        "                                            optimizer, criterion)\n",
        "    valid_epoch_loss, valid_epoch_acc = validate(net, valid_loader,  \n",
        "                                                criterion)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    valid_loss.append(valid_epoch_loss)\n",
        "    train_acc.append(train_epoch_acc)\n",
        "    valid_acc.append(valid_epoch_acc)\n",
        "    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n",
        "    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n",
        "    # save the best net:\n",
        "    save_best_model(\n",
        "        valid_epoch_loss, epoch, net, optimizer, criterion\n",
        "    )\n",
        "    print('-'*50)\n",
        "    \n",
        "# save the trained net weights for a final time - need to submit this with the poster\n",
        "save_model(epochs, net, optimizer, criterion)\n",
        "save_plots(train_acc, valid_acc, train_loss, valid_loss)\n",
        "print('TRAINING COMPLETE')\n",
        "    "
      ],
      "metadata": {
        "id": "NYyd9Ysv0X6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction / Evaluation \n",
        "\n",
        "Evaluation by using:\n",
        "1. accurancy, precision and recall (PR curve)\n",
        "2. confusion matrix (visualised)\n",
        "3. ROC (optional)"
      ],
      "metadata": {
        "id": "CY9XHfD4y8yD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the best model checkpoint\n",
        "best_model_cp = torch.load('outputs/best_model.pth')\n",
        "best_model_epoch = best_model_cp['epoch']\n",
        "print(f\"Best model was saved at {best_model_epoch} epochs\\n\")\n",
        "\n",
        "# load the last model checkpoint\n",
        "last_model_cp = torch.load('outputs/final_model.pth')\n",
        "last_model_epoch = last_model_cp['epoch']\n",
        "print(f\"Last model was saved at {last_model_epoch} epochs\\n\")"
      ],
      "metadata": {
        "id": "uBPB0tHgb-Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    print('===== Testing =====')\n",
        "    valid_running_correct = 0\n",
        "    counter = 0\n",
        "    nb_classes = 3\n",
        "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            counter += 1\n",
        "            \n",
        "            X_test, y_test = data\n",
        "            X_test = X_test.to(device)\n",
        "            y_test = y_test.to(device)\n",
        "            # forward pass\n",
        "            outputs = model(X_test)\n",
        "\n",
        "            # calculate the accuracy\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            valid_running_correct += (preds == y_test).sum().item()\n",
        "            \n",
        "            # get true and predict:\n",
        "            for t, p in zip(y_test.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "        \n",
        "    # loss and accuracy for the complete epoch\n",
        "    final_acc = 100. * (valid_running_correct / len(test_loader.dataset))\n",
        "    return final_acc, confusion_matrix"
      ],
      "metadata": {
        "id": "5SJqrn2IcJBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test two ckpts\n",
        "\n",
        "def test_last_model(model, checkpoint, test_loader):\n",
        "    print('Loading last epoch saved model weights...')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    test_acc, confusion_matrix = test(model, test_loader)\n",
        "    print(f\"Last epoch saved model accuracy: {test_acc:.3f}\")\n",
        "    creat_viz_cm(confusion_matrix, label2class)\n",
        "\n",
        "# test the best epoch saved model\n",
        "def test_best_model(model, checkpoint, test_loader):\n",
        "    print('Loading best epoch saved model weights...')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    test_acc, confusion_matrix = test(model, test_loader)\n",
        "    print(f\"Best epoch saved model accuracy: {test_acc:.3f}\")\n",
        "    creat_viz_cm(confusion_matrix, label2class)"
      ],
      "metadata": {
        "id": "iRQ0VP1VB1d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run test\n",
        "test_last_model(net, last_model_cp, test_loader)\n",
        "\n",
        "test_best_model(net, best_model_cp, test_loader)"
      ],
      "metadata": {
        "id": "B3Ra82A5B1We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bpEJmPk0B1UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwZZeCSbB1KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comapre with models in torchvision (resnet18 etc...)"
      ],
      "metadata": {
        "id": "r8wvLzv5ahIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models"
      ],
      "metadata": {
        "id": "pfqOM6AKaOv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True) \n",
        "\n",
        "# model = models.resnet152(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "30059e7f76554edeaebfde0ed47cb22d",
            "0f32b89aee684497aeda207ea4168afb",
            "51ed36da4009415eb75ea2e10b540dfc",
            "74fdfbff676e4c3c830f45592759cc47",
            "582f0ee5e71a49aba6e4cf92e4fa5159",
            "a217e1bf7c1144449e17af9deb1be2b3",
            "94dd1f666dfb401c972d62063d271db8",
            "c35923bf34be437cb4057856dd450651",
            "eebff500f8174452a20b5f7afbaae825",
            "56fd522c16f5433ca34dc92971b713d5",
            "9d624b2e9ea14d87ad56380ba0f6b9c6"
          ]
        },
        "id": "16sAOirB2jlk",
        "outputId": "31a1b233-36b0-4ef9-c10b-a04a75646d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30059e7f76554edeaebfde0ed47cb22d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.eval()\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "pzj7ehur2jje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z1Obj_MA2jc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SkEC8GFS2iI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YmXsuMrmaR1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8G5cwE4paW-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z1L8oNCwaXfm"
      }
    }
  ]
}